import torch
import torch.nn.functional as F
import numpy as np
import time
import os
from tqdm import tqdm

class ComprehensiveMetricsCalculator:
    """å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨ï¼šFPS, aACC, mACC"""
    
    def __init__(self, model, device, input_shape=(512, 512), num_classes=21):
        self.model = model
        self.device = device
        self.input_shape = input_shape
        self.num_classes = num_classes
        
    def calculate_fps(self, test_samples=100, warmup_samples=10):
        """è®¡ç®—FPS (æ¯ç§’å¸§æ•°)"""
        print("ğŸš€ å¼€å§‹è®¡ç®—FPS...")
        
        self.model.eval()
         
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        dummy_input = torch.randn(1, 3, *self.input_shape).to(self.device)
        
        # é¢„çƒ­GPU
        with torch.no_grad():
            for _ in range(warmup_samples):
                _ = self.model(dummy_input)
        
        # åŒæ­¥GPUï¼ˆå¦‚æœä½¿ç”¨CUDAï¼‰
        if self.device.type == 'cuda':
            torch.cuda.synchronize()
        
        # å¼€å§‹è®¡æ—¶
        start_time = time.time()
        
        with torch.no_grad():
            for _ in range(test_samples):
                output = self.model(dummy_input)
        
        # åŒæ­¥GPU
        if self.device.type == 'cuda':
            torch.cuda.synchronize()
        
        end_time = time.time()
        
        # è®¡ç®—FPS
        total_time = end_time - start_time
        fps = test_samples / total_time
        avg_inference_time = (total_time / test_samples) * 1000  # ms
        
        print(f"âœ… FPSè®¡ç®—å®Œæˆ:")
        print(f"   æµ‹è¯•æ ·æœ¬æ•°: {test_samples}")
        print(f"   æ€»è€—æ—¶: {total_time:.4f}s")
        print(f"   å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.2f}ms")
        print(f"   FPS: {fps:.2f} frames/sec")
        
        return fps, avg_inference_time
    
    def calculate_accuracy_metrics(self, dataloader, max_samples=None):
        """è®¡ç®—aACCå’ŒmACC"""
        print("ğŸ“Š å¼€å§‹è®¡ç®—å‡†ç¡®ç‡æŒ‡æ ‡...")
        
        self.model.eval()
        
        # åˆå§‹åŒ–è®¡æ•°å™¨
        total_correct_pixels = 0
        total_pixels = 0
        class_correct = np.zeros(self.num_classes, dtype=np.int64)
        class_total = np.zeros(self.num_classes, dtype=np.int64)
        
        processed_samples = 0
        
        with torch.no_grad():
            pbar = tqdm(dataloader, desc="è®¡ç®—å‡†ç¡®ç‡")
            for batch_idx, batch in enumerate(pbar):
                # å¦‚æœè®¾ç½®äº†æœ€å¤§æ ·æœ¬æ•°é™åˆ¶
                if max_samples and processed_samples >= max_samples:
                    break
                
                # ğŸ”¥ ä¿®æ”¹è¿™é‡Œï¼šå®‰å…¨è§£åŒ…æ•°æ®
                try:
                    if len(batch) == 2:
                        images, labels = batch
                    elif len(batch) == 3:
                        images, labels, _ = batch  # å¯èƒ½æœ‰é¢å¤–çš„ä¿¡æ¯
                    elif len(batch) > 3:
                        images, labels = batch[0], batch[1]  # åªå–å‰ä¸¤ä¸ª
                    else:
                        print(f"âš ï¸ æ„å¤–çš„batchæ ¼å¼ï¼Œé•¿åº¦: {len(batch)}")
                        continue
                except Exception as e:
                    print(f"âš ï¸ æ•°æ®è§£åŒ…é”™è¯¯: {e}")
                    continue
                
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                # æ¨¡å‹é¢„æµ‹
                outputs = self.model(images)
                
                # å¦‚æœè¾“å‡ºå°ºå¯¸ä¸æ ‡ç­¾ä¸åŒ¹é…ï¼Œè¿›è¡Œæ’å€¼
                if outputs.shape[2:] != labels.shape[1:]:
                    outputs = F.interpolate(
                        outputs, 
                        size=labels.shape[1:], 
                        mode='bilinear', 
                        align_corners=True
                    )
                
                # è·å–é¢„æµ‹ç±»åˆ«
                predictions = torch.argmax(outputs, dim=1)
                
                # è®¡ç®—æ•´ä½“åƒç´ å‡†ç¡®ç‡ (aACC)
                correct_pixels = (predictions == labels).sum().item()
                total_correct_pixels += correct_pixels
                total_pixels += labels.numel()
                
                # è®¡ç®—å„ç±»åˆ«å‡†ç¡®ç‡ (ç”¨äºmACC)
                for class_id in range(self.num_classes):
                    # æ‰¾åˆ°çœŸå®æ ‡ç­¾ä¸ºå½“å‰ç±»åˆ«çš„åƒç´ 
                    class_mask = (labels == class_id)
                    
                    if class_mask.sum() > 0:  # å¦‚æœè¯¥ç±»åˆ«åœ¨å½“å‰batchä¸­å­˜åœ¨
                        # è¯¥ç±»åˆ«çš„æ­£ç¡®é¢„æµ‹æ•°é‡
                        class_correct_pred = (predictions[class_mask] == class_id).sum().item()
                        class_correct[class_id] += class_correct_pred
                        class_total[class_id] += class_mask.sum().item()
            
                processed_samples += images.shape[0]
                
                # æ›´æ–°è¿›åº¦æ¡
                current_aacc = (total_correct_pixels / total_pixels) * 100
                pbar.set_postfix({
                    'aACC': f'{current_aacc:.2f}%',
                    'Samples': processed_samples
                })
        
        # è®¡ç®—æœ€ç»ˆçš„aACC
        aacc = (total_correct_pixels / total_pixels) * 100
        
        # è®¡ç®—mACC
        class_accuracies = []
        for class_id in range(self.num_classes):
            if class_total[class_id] > 0:
                class_acc = class_correct[class_id] / class_total[class_id]
                class_accuracies.append(class_acc)
            else:
                # å¦‚æœæŸä¸ªç±»åˆ«åœ¨éªŒè¯é›†ä¸­ä¸å­˜åœ¨ï¼Œä¸è®¡å…¥mACCè®¡ç®—
                print(f"âš ï¸ è­¦å‘Š: ç±»åˆ« {class_id} åœ¨éªŒè¯é›†ä¸­æœªå‡ºç°")
        
        macc = np.mean(class_accuracies) * 100 if class_accuracies else 0
        
        print(f"âœ… å‡†ç¡®ç‡è®¡ç®—å®Œæˆ:")
        print(f"   å¤„ç†æ ·æœ¬æ•°: {processed_samples}")
        print(f"   æ€»åƒç´ æ•°: {total_pixels:,}")
        print(f"   æ­£ç¡®åƒç´ æ•°: {total_correct_pixels:,}")
        print(f"   aACC (æ•´ä½“åƒç´ å‡†ç¡®ç‡): {aacc:.2f}%")
        print(f"   æœ‰æ•ˆç±»åˆ«æ•°: {len(class_accuracies)}/{self.num_classes}")
        print(f"   mACC (å¹³å‡ç±»åˆ«å‡†ç¡®ç‡): {macc:.2f}%")
        
        # è¿”å›è¯¦ç»†ç»“æœ
        return {
            'aacc': aacc,
            'macc': macc,
            'class_accuracies': class_accuracies,
            'total_pixels': total_pixels,
            'correct_pixels': total_correct_pixels,
            'processed_samples': processed_samples
        }
    
    def calculate_all_metrics(self, dataloader, max_samples=None):
        """è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ï¼šFPS + aACC + mACC"""
        print("\n" + "="*60)
        print("ğŸ¯ å¼€å§‹å®Œæ•´æ€§èƒ½è¯„ä¼°...")
        
        # 1. è®¡ç®—FPS
        fps, avg_time = self.calculate_fps()
        
        # 2. è®¡ç®—å‡†ç¡®ç‡æŒ‡æ ‡
        accuracy_results = self.calculate_accuracy_metrics(dataloader, max_samples)
        
        # æ•´åˆæ‰€æœ‰ç»“æœ
        all_metrics = {
            'fps': fps,
            'avg_inference_time_ms': avg_time,
            'aacc': accuracy_results['aacc'],
            'macc': accuracy_results['macc'],
            'total_pixels': accuracy_results['total_pixels'],
            'correct_pixels': accuracy_results['correct_pixels'],
            'processed_samples': accuracy_results['processed_samples']
        }
        
        return all_metrics
    
    def save_metrics_report(self, metrics, save_dir, model_name="UNet"):
        """ä¿å­˜è¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š"""
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        # ä¿å­˜JSONæ ¼å¼
        import json
        json_path = os.path.join(save_dir, "final_metrics.json")
        with open(json_path, 'w') as f:
            json.dump(metrics, f, indent=2)
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_path = os.path.join(save_dir, "evaluation_report.txt")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"{model_name} æ¨¡å‹è¯„ä¼°æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            
            f.write("ğŸ“Š æ€§èƒ½æŒ‡æ ‡:\n")
            f.write(f"ğŸš€ FPS (æ¨ç†é€Ÿåº¦): {metrics['fps']:.2f} frames/sec\n")
            f.write(f"â±ï¸ å¹³å‡æ¨ç†æ—¶é—´: {metrics['avg_inference_time_ms']:.2f} ms/frame\n")
            f.write(f"ğŸ¯ aACC (æ•´ä½“åƒç´ å‡†ç¡®ç‡): {metrics['aacc']:.2f}%\n")
            f.write(f"ğŸ“ˆ mACC (å¹³å‡ç±»åˆ«å‡†ç¡®ç‡): {metrics['macc']:.2f}%\n\n")
            
            f.write("ğŸ“‹ è¯¦ç»†ç»Ÿè®¡:\n")
            f.write(f"- å¤„ç†æ ·æœ¬æ•°: {metrics['processed_samples']}\n")
            f.write(f"- æ€»åƒç´ æ•°: {metrics['total_pixels']:,}\n")
            f.write(f"- æ­£ç¡®åƒç´ æ•°: {metrics['correct_pixels']:,}\n\n")
            
            f.write("ğŸ“ æŒ‡æ ‡è¯´æ˜:\n")
            f.write("- FPS: æ¯ç§’èƒ½å¤„ç†çš„å›¾ç‰‡å¸§æ•°ï¼Œè¶Šé«˜è¶Šå¥½\n")
            f.write("- aACC: æ‰€æœ‰åƒç´ çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œåæ˜ æ•´ä½“æ€§èƒ½\n")
            f.write("- mACC: å„ç±»åˆ«å‡†ç¡®ç‡çš„å¹³å‡å€¼ï¼Œåæ˜ ç±»åˆ«å¹³è¡¡æ€§èƒ½\n")
        
        print(f"ğŸ“ è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜:")
        print(f"   JSONæ ¼å¼: {json_path}")
        print(f"   è¯¦ç»†æŠ¥å‘Š: {report_path}")
        
        return json_path, report_path